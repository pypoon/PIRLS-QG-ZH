{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "model_id = \"hfl/llama-3-chinese-8b-instruct-v2\"\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "b0sEGPDMShcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_forming_zero(instruction, passage):\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": \"你是一個能幹的閱讀理解問題生成器，始終遵循給定的說明和要求來生成問題。\"},\n",
        "    {\"role\": \"user\", \"content\": f\"{instruction}\\n文章:{passage}\"},\n",
        "]\n",
        "  prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "  return prompt\n",
        "\n",
        "def prompt_forming_few(instruction, example, passage):\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": \"你是一個能幹的閱讀理解問題生成器，始終遵循給定的說明和要求來生成問題。\"},\n",
        "    {\"role\": \"user\", \"content\": f\"{instruction}\\n{example}\\n文章:{passage}\"},\n",
        "]\n",
        "  prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "  return prompt\n",
        "\n",
        "def bot(prompt):\n",
        "  terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "  print(prompt)\n",
        "  outputs = pipeline(\n",
        "      prompt,\n",
        "      max_new_tokens=200,\n",
        "      eos_token_id=terminators,\n",
        "      do_sample=True,\n",
        "      temperature=0.6,\n",
        "      top_p=0.9,\n",
        "      )\n",
        "  print(outputs[0][\"generated_text\"][len(prompt):])\n",
        "  return outputs[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "\n",
        "def generate_question(article, prompt_list, level, way):\n",
        "    result_list = []\n",
        "    if level == 1:\n",
        "      instruction = prompt_list[0]\n",
        "      #due to copyright, we are unable to display the article content\n",
        "      example = \"\"\"範例文章及相應的範例問題(請參考範例來創作問題):{範例文章:{}\n",
        "PIRLS第一層次範例問題1:{開學第一天老師做了什麼?\n",
        "答案: 介紹自己}\n",
        "\n",
        "PIRLS第一層次範例問題2:{小息時學生的狀態怎麼樣？\n",
        "答案: 精神興奮}\n",
        "\n",
        "PIRLS第一層次範例問題3:{文中惡霸能屢屢得手的原因是什麼？\n",
        "答案: 弱者不敢告發他們}\n",
        "\n",
        "PIRLS第一層次範例問題4:{惡霸大威受到什麼懲罰？\n",
        "答案: 被老師狠狠教訓一番}\n",
        "\n",
        "PIRLS第一層次範例問題5:{文中校園惡霸什麼形象？\n",
        "答案: 身體健碩}}\"\"\"\n",
        "\n",
        "    elif level == 2:\n",
        "      instruction = prompt_list[1]\n",
        "      example = \"\"\"範例文章及相應的範例問題(請參考範例來創作問題):{範例文章:{}\n",
        "PIRLS第二層次範例問題1:{莉莉最好的朋友是谁\n",
        "答案: 鲍思高}\n",
        "\n",
        "PIRLS第二層次範例問題2:{为什么说莉莉家很有钱？\n",
        "答案: 因为她的爸爸是一个成功的商人}\n",
        "\n",
        "PIRLS第二層次範例問題3:{为什么鲍勃没有从他的农田里赚到钱\n",
        "答案: 因为今年有很严重的飓风}\n",
        "\n",
        "PIRLS第二層次範例問題4:{为什么莉莉让她的妈妈把她们的食物、衣服和玩具送给鲍勃？\n",
        "答案: 因为她想要帮助有需要的人/因为她认为鲍勃一家比她更需要这些东西/因为她为鲍勃的遭遇感到难过}\n",
        "\n",
        "PIRLS第二層次範例問題5:{为什么莉莉不再浪费食物了？\n",
        "答案: 因为她知道了食物的价值}}\"\"\"\n",
        "\n",
        "    elif level == 3:\n",
        "      instruction = prompt_list[2]\n",
        "      example = \"\"\"範例文章及相應的範例問題(請參考範例來創作問題):{範例文章:{}\n",
        "PIRLS第三層次範例問題1:{脑先生和手小姐的性格是什么？\n",
        "答案: 知错能改}\n",
        "\n",
        "PIRLS第三層次範例問題2:{脑先生和手小姐吵架后，主人有什么感受？\n",
        "答案: 既苦恼又肚子饿}\n",
        "\n",
        "PIRLS第三層次範例問題3:{脑先生和手小姐存在是为了什么？\n",
        "答案: 为主人服务}\n",
        "\n",
        "PIRLS第三層次範例問題4:{脑先生为什么觉得自己较厉害？\n",
        "答案: 因为他觉得自己负责控制手小姐活动}\n",
        "\n",
        "PIRLS第三層次範例問題5:{手小姐为什么觉得自己较厉害？\n",
        "答案: 她认为没有她执行动作，脑先生什么也做不了，只能空想。}}\"\"\"\n",
        "\n",
        "    elif level == 4:\n",
        "      instruction = prompt_list[3]\n",
        "      example = \"\"\"範例文章及相應的範例問題(請參考範例來創作問題):{範例文章:{}\n",
        "PIRLS第四層次範例問題1:{我们可以怎么形容机器人？\n",
        "答案: 很有用}\n",
        "\n",
        "PIRLS第四層次範例問題2:{作者发现房中的一切之后有什么感觉？\n",
        "答案: 震惊}\n",
        "\n",
        "PIRLS第四層次範例問題3:{你会怎么形容作者没有清理前的房间？\n",
        "答案: 震耳欲聋/吵闹/杂乱}\n",
        "\n",
        "PIRLS第四層次範例問題4:{这个故事教会了我们什么？\n",
        "答案: 我们应该要保持清洁和干净}\n",
        "\n",
        "PIRLS第四層次範例問題5:{你觉得最后作者的妈妈会感觉怎么样？\n",
        "答案: 她对作者很骄傲/她觉得作者做的很棒/她很开心作者终于对自己的房间负责任}}\"\"\"\n",
        "\n",
        "    if way == \"zero\":\n",
        "      prompt = prompt_forming_zero(instruction, article)\n",
        "    elif way == \"few\":\n",
        "      prompt = prompt_forming_few(instruction, example, article)\n",
        "    output = bot(prompt=prompt)\n",
        "    result_list.append([article, output, level])\n",
        "    return result_list\n",
        "\n",
        "def process(article_data,prompt_path, way):\n",
        "      prompt_list = []\n",
        "      temp_prompt_data = pd.read_excel(prompt_path)\n",
        "      for n in range(len(temp_prompt_data)):\n",
        "          prompt_list.append(temp_prompt_data['prompt'][n])\n",
        "      result_list = []\n",
        "      for n in range(len(article_data)):\n",
        "          print(f\"{n+1}/50:\")\n",
        "          article = article_data['clean_article'][n]\n",
        "          result_list.extend(generate_question(article, prompt_list, level=1, way=way))\n",
        "          result_list.extend(generate_question(article, prompt_list, level=2, way=way))\n",
        "          result_list.extend(generate_question(article, prompt_list, level=3, way=way))\n",
        "          result_list.extend(generate_question(article, prompt_list, level=4, way=way))\n",
        "      df = pd.DataFrame(result_list, columns = ['article', 'question', 'required level'])\n",
        "      if way == \"zero\":\n",
        "          df.to_excel(f\"zero.xlsx\", index=None)\n",
        "      elif way == \"few\":\n",
        "          df.to_excel(f\"few.xlsx\", index=None)\n",
        "\n",
        "article_data = pd.read_excel(\"test article.xlsx\")\n",
        "prompt_path = \"QAG_prompt_zero.xlsx\"\n",
        "way = \"zero\"\n",
        "process(article_data, prompt_path, way)"
      ],
      "metadata": {
        "id": "wjaqeiMyShf2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}