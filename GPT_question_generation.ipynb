{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MihgOaMrUug7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    os.environ.get(\"OPENAI_API_KEY\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_question(article, prompt_list, level):\n",
        "    result_list = []\n",
        "    if level == 1:\n",
        "      instruction = prompt_list[0]\n",
        "\n",
        "    elif level == 2:\n",
        "      instruction = prompt_list[1]\n",
        "\n",
        "    elif level == 3:\n",
        "      instruction = prompt_list[2]\n",
        "\n",
        "    elif level == 4:\n",
        "      instruction = prompt_list[3]\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"你是一個能幹的閱讀理解問題生成器，始終遵循給定的說明和要求來生成問題。\"},\n",
        "             {\"role\": \"user\", \"content\": f\"{instruction}\\n文章:{article}\"}\n",
        "            ],\n",
        "    max_tokens=200,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9\n",
        "    )\n",
        "    output = chat_completion.choices[0].message.content\n",
        "    print(output)\n",
        "    result_list.append([article, output, level])\n",
        "    return result_list\n",
        "\n",
        "def process(article_data,prompt_path):\n",
        "      prompt_list = []\n",
        "      temp_prompt_data = pd.read_excel(prompt_path)\n",
        "      for n in range(len(temp_prompt_data)):\n",
        "          prompt_list.append(temp_prompt_data['prompt'][n])\n",
        "      result_list = []\n",
        "      for n in range(len(article_data)):\n",
        "          print(f\"{n+1}/50:\")\n",
        "          article = article_data['clean_article'][n]\n",
        "          result_list.extend(generate_question(article, prompt_list, level=1))\n",
        "          result_list.extend(generate_question(article, prompt_list, level=2))\n",
        "          result_list.extend(generate_question(article, prompt_list, level=3))\n",
        "          result_list.extend(generate_question(article, prompt_list, level=4))\n",
        "      df = pd.DataFrame(result_list, columns = ['article', 'question', 'required level'])\n",
        "      df.to_excel(\"GPT4o(zero).xlsx\", index=None)\n",
        "\n",
        "article_data = pd.read_excel(\"test article.xlsx\")\n",
        "prompt_path = \"QAG_prompt_zero.xlsx\"\n",
        "process(article_data, prompt_path)"
      ],
      "metadata": {
        "id": "ISF4a7utYcAW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}